# 大数据最新面试题，2021年面试题及答案汇总

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)



### 1、为什么会产生RDD

什么是窄依赖，宽依赖

窄依赖指的是每一个父RDD的partition最多被子RDD的一个Partition使用

一对一

宽依赖指的是多个子RDD的partition会依赖于同一个父RDD的partition

多对一


### 2、Hadoop的shuffle过程

**Map端的shuffle**

Map端会处理输入数据并产生中间结果，这个中间结果会写到本地磁盘，而不是HDFS。每个Map的输出会先写到内存缓冲区中，当写入的数据达到设定的阈值时，系统将会启动一个线程将缓冲区的数据写到磁盘，这个过程叫做spill。

在spill写入之前，会先进行二次排序，首先根据数据所属的partition进行排序，然后每个partition中的数据再按key来排序。partition的目是将记录划分到不同的Reducer上去，以期望能够达到负载均衡，以后的Reducer就会根据partition来读取自己对应的数据。接着运行combiner(如果设置了的话)，combiner的本质也是一个Reducer，其目的是对将要写入到磁盘上的文件先进行一次处理，这样，写入到磁盘的数据量就会减少。最后将数据写到本地磁盘产生spill文件(spill文件保存在{mapred.local.dir}指定的目录中，Map任务结束后就会被删除)。

最后，每个Map任务可能产生多个spill文件，在每个Map任务完成前，会通过多路归并算法将这些spill文件归并成一个文件。至此，Map的shuffle过程就结束了。

**Reduce端的shuffle**

Reduce端的shuffle主要包括三个阶段，copy、sort(merge)和reduce。

首先要将Map端产生的输出文件拷贝到Reduce端，但每个Reducer如何知道自己应该处理哪些数据呢？

因为Map端进行partition的时候，实际上就相当于指定了每个Reducer要处理的数据(partition就对应了Reducer)，所以Reducer在拷贝数据的时候只需拷贝与自己对应的partition中的数据即可。

每个Reducer会处理一个或者多个partition，但需要先将自己对应的partition中的数据从每个Map的输出结果中拷贝过来。

接下来就是sort阶段，也成为merge阶段，因为这个阶段的主要工作是执行了归并排序。

从Map端拷贝到Reduce端的数据都是有序的，所以很适合归并排序。

最终在Reduce端生成一个较大的文件作为Reduce的输入。

最后就是Reduce过程了，在这个过程中产生了最终的输出结果，并将其写到HDFS上。


### 3、hive底层与数据库交互原理

hive有一套自己的 sql解析引擎成为metastore，存储在MySQL中可以将sql转化为mrjob任务执行


### 4、Hbase的rowKey怎么创建比较好？列簇怎么创建比较好？



rowKey最好要创建有规则的rowKey，即最好是有序的。

经常需要批量读取的数据应该让他们的rowkey连续；

将经常需要作为条件查询的关键词组织到rowkey中；

列族的创建：

按照业务特点，把数据归类，不同类别的放在不同列族

用mapreduce怎么处理数据倾斜问题

本质：让各分区的数据分布均匀

可以根据业务特点，设置合适的partition策略

如果事先根本不知道数据的分布规律，利用随机抽样器抽样后生成partition策略再处理



### 5、combiner出现在哪个过程

出现在map阶段的map方法后，shuffle过程


### 6、HBase的特点是什么？

**1、** hbase是一个分布式的基于列式存储的数据库，基于hadoop的HDFS存储，zookeeper进行管理。

**2、** hbase适合存储半结构化或非结构化数据，对于数据结构字段不够确定或者杂乱无章很难按一个概念去抽取的数据。

**3、** hbase为null的记录不会被存储。

**4、** 基于的表包括rowkey，时间戳和列族。新写入数据时，时间戳更新，同时可以查询到以前的版本。

**5、** hbase是主从结构。Hmaster作为主节点，hregionserver作为从节点。


### 7、宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。

如果是HMaster宕机，HMaster没有单点问题，HBase中可以启动多个HMaster，通过Zookeeper的Master Election机制保证总有一个Master运行。即ZooKeeper会保证总会有一个HMaster在对外提供服务。


### 8、HBase简单读写流程？

读：

找到要读数据的region所在的RegionServer，然后按照以下顺序进行读取：先去BlockCache读取，若BlockCache没有，则到Memstore读取，若Memstore中没有，则到HFile中去读。

写：

找到要写数据的region所在的RegionServer，然后先将数据写到WAL(Write-Ahead Logging，预写日志系统)中，然后再将数据写到Memstore等待刷新，回复客户端写入完成。


### 9、使用zk来连接集群

./Kafka-console-consumer.sh --Zookeeper node01:2181,node2:2181,node3:2181 --from-beginning --topic test


### 10、是客户端还是Namenode决定输入的分片？

这并不是客户端决定的，在配置文件中以及决定分片细则。


### 11、hive如何控制权限
### 12、搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。
### 13、数据的三范式
### 14、什么是Kafka？
### 15、mapred.job.tracker命令的作用？
### 16、当Job Tracker宕掉时，Namenode会发生什么？
### 17、fsimage和edit的区别？
### 18、hbase中表的特点
### 19、RDD有哪些缺陷？
### 20、这会导致安全问题吗？
### 21、Hive与关系型数据库的关系？
### 22、海量日志数据，提取出某日访问百度次数最多的那个IP。
### 23、hive数仓开发的基本流程
### 24、怎么样才能实现去掉reduce阶段
### 25、sqoop在导入到MySQL中，如果不重复导入数据，如果数据存在问题，sqoop如何处理？
### 26、Hbase行键列族的概念，物理模型，表的设计原则？
### 27、什么是DAG
### 28、hive的内表和外表
### 29、怎么在海量数据中找出重复次数最多的一个？
### 30、hive有哪些方式保存元数据，各有哪些优点
### 31、请列出你所知道的hadoop调度器，并简要说明其工作方法？
### 32、Master文件是否提供了多个入口？




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)


## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "大厂面试题")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png"大厂面试题")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
