# 大数据最新2021年面试题附答案解析，大汇总

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)



### 1、Kafka怎么保证消息不丢失机制

producer：分为同步模式与异步模式，同步模式效率低，异步模式效率高

Kafka的ack机制，在Kafkafa发送数据的时候，每次发送消息都会有一个确认反馈机制，确保消息正常能够被收到

同步模式：ack机制能够保数据的不丢失 ，不建议设置为0

producer.type=sync

request.required.acks=1

异步模式：通过buffer来进行控制数据的发送，时间阈值与消息数量阈值，如果buffer满了数据未发送，如果设置立即清理模式，风险很大，一定设置为阻塞模式

producer.type=sync

request.required.acks=1

queue.buffering.max.ms=5000

queue.buffering.max.messages=10000

queue.enqueue.timeout.ms=-1

batch.num.messages=200


### 2、Spark为什么要持久化，一般什么场景下要进行persist操作？

为什么要进行持久化？

spark所有复杂一点的算法都会有persist身影，spark默认数据放在内存，spark很多内容都是放在内存的，非常适合高速迭代，1000个步骤只有第一个输入数据，中间不产生临时数据，但分布式系统风险很高，所以容易出错，就要容错，rdd出错或者分片可以根据血统算出来，如果没有对父rdd进行persist 或者cache的化，就需要重头做。

**以下场景会使用persist**

**1、** 某个步骤计算非常耗时，需要进行persist持久化

**2、** 计算链条非常长，重新恢复要算很多步骤，很好使，persist

**3、** checkpoint所在的rdd要持久化persist。checkpoint前，要持久化，写个rdd.cache或者rdd.persist，将结果保存起来，再写checkpoint操作，这样执行起来会非常快，不需要重新计算rdd链条了。checkpoint之前一定会进行persist。

**4、** shuffle之后要persist，shuffle要进性网络传输，风险很大，数据丢失重来，恢复代价很大

**5、** shuffle之前进行persist，框架默认将数据持久化到磁盘，这个是框架自动做的。


### 3、flush的过程

flush是在内存的基础上进行的，首先写入文件的时候，会先将文件写到内存中，当内存写满的时候，一次性的将文件全部都写到硬盘中去保存，并清空缓存中的文件，


### 4、Redis，传统数据库，hbase，hive每个之间的区别

Redis是缓存

hbase是列式数据库，存在hdfs上，写入速度快，数据量大，查询速度快

hive是数据仓库，是用来分析数据，不是增删改查数据的


### 5、hive内部表和外部表的区别

Hive 向内部表导入数据时，会将数据移动到数据仓库指向的路径；若是外部表，数据的具体存放目录由用户建表时指定

在删除表的时候，内部表的元数据和数据会被一起删除，

而外部表只删除元数据，不删除数据。

这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。


### 6、fs.mapr.working.dir只是单一的目录？

fs.mapr.working.dir只是一个目录。


### 7、hive 跟hbase的区别

共同点都是用hadoop作为底层存储

区别：hive是为了减少mrjobs编写工作的批处理系统，处理速度慢。hive本身不存储数据和计算数据，依赖于hadoop，纯逻辑表

hbase是为了hadoop对实时操作的缺陷的项目，处理速度快，是物理表，提供一个超大的内存hash表，方便查询操作

如果全表扫描用 hive+hadoop

如果用索引查询与hbase+hadoop

是处理数据库文件还是读取文本文件

先读取文本文件进行清洗，然后放入hdfs，进行处理

或者直接读取MySQL中格式化数据


### 8、hadoop中常用的数据压缩算法

Lzo

Gzip

Default

Snapyy

如果要对数据进行压缩，最好是将原始数据转为SequenceFile 或者 Parquet File（spark）


### 9、存储特点

存储时，按照rowkey的字典序排列存储，设计key时，要充分排序存储这个特性，将经常一起读取的行存储放到一起


### 10、有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。

方案：顺序读文件中，对于每个词x，取hash(x)P00，然后按照该值存到5000个小文件（记为x0,x1,…x4999）中。这样每个文件大概是200k左右。

如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。

对每个小文件，统计每个文件中出现的词以及相应的频率（可以采用trie树/hash_map等），并取出出现频率最大的100个词（可以用含100个结点的最小堆），并把100个词及相应的频率存入文件，这样又得到了5000个文件。下一步就是把这5000个文件进行归并（类似与归并排序）的过程了。


### 11、为什么要用flume导入hdfs，hdfs的架构是怎样的？
### 12、hive底层与数据库交互原理
### 13、hive如何控制权限
### 14、hive如何优化
### 15、如何确定hadoop集群的健康状态
### 16、Hadoop-env.sh文件当下的位置？
### 17、假设公司要建一个数据中心，你会如何处理？
### 18、什么是spark
### 19、腾讯面试题：给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？
### 20、fsimage和edit的区别？
### 21、为什么SSH本地主机需要密码？
### 22、mapreduce作业，不让reduce输出，用什么代替reduce的功能。
### 23、宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。
### 24、怎么设置RDD cache
### 25、请列出你所知道的hadoop调度器，并简要说明其工作方法？
### 26、请列出你所知道的hadoop调度器，并简要说明其工作方法
### 27、请说明hive中Sort By、Order By、Cluster By，Distribute By各代表什么意思？
### 28、是否可以在Windows上运行Hadoop？
### 29、如何在浏览器中查找Namenode？
### 30、Namenode、Job tracker和task tracker的端口号是？
### 31、hdfs-site.xml的3个主要属性？
### 32、如何知道消费者消费到哪一条消息了？




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)


## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
