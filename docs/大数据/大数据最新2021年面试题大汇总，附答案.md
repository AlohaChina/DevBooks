# 大数据最新2021年面试题大汇总，附答案

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://github.com/souyunku/DevBooks/blob/master/docs/index.md)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png)



### 1、insert into 和override write区别

insert into：将某一个表的数据写到另一个表

override write ：覆盖之前的表


### 2、过滤器有什么用途：

增强hbase查询数据的功能

减少服务端返回给客户端的数据量

reduce之后数据的输出量有多大（结合具体场景，比如pi）

Sca阶段的增强日志（1.5T—2T）

过滤性质的mr程序，输出比输入少

解析性质的mr程序，输出比输入多（找共同朋友）


### 3、spark的优化怎么做？

spark调优比较复杂，但是大体可以分为三个方面来进行

平台层面的调优：防止不必要的jar包分发，提高数据的本地性，选择高效的存储格式如parquet

应用程序层面的调优：过滤操作符的优化降低过多小任务，降低单条记录的资源开销，处理数据倾斜，复用RDD进行缓存，作业并行化执行等等

JVM层面的调优：设置合适的资源量，设置合理的JVM，启用高效的序列化方法如kyro，增大off head内存等等


### 4、描述一下hadoop中，有哪些地方使用到了缓存机制，作用分别是什么？

Shuffle中

Hbase----客户端/regionserver


### 5、为什么hive的分区

为了避免select扫描全表，hive提出了分区表partitionedby的概念，给文件归类打上表示

**静态分区：**

单分区建表

create table par_tab(name string,nation string) partitioned by (sex string) row format delimited fields terminated by ‘,’;

加载：load data local inpath ‘/hdfs/…’ into table par_tab partition(sex=‘man’)

在创建分区表的时候，系统会在hive数据仓库默认路径/user/hive/warehouse/创建目录，在创建sex=man的目录，最后在分区名下存放实际的数据文件

**多分区建表**

create table par_tab(name string,nation string) partitioned by (sex string,dt string) row format delimited fields terminated by ',';

load data local inpath '/hdfs/...' into table par_tab partition(sex='man',dt="2019-08-08")

当我们查询所有的man时候，man一下的所有日期下的数据都会被查出来；如果只查询日期分区，那么hive会对路径进行修剪，从而只扫描日期分区，性别分区不做过滤

动态分区

动态分区与静态分区区别就是不指定分区目录，有系统自己选择

开启动态分区 set hive.exec.dynamic.partition=true


### 6、Hive与关系型数据库的关系？

没有关系，hive是数据仓库，不能和数据库一样进行实时的CRUD操作。

是一次写入多次读取的操作，可以看成是ETL的工具。


### 7、简单说一下hadoop的map-reduce模型

首先map task会从本地文件系统读取数据，转换成key-value形式的键值对集合，使用的是hadoop内置的数据类型，如Text，Longwritable等。

将键值对集合输入mapper进行业务处理过程，将其转化成需要的key-value再输出。

之后会进行一个partition分区操作，默认使用的是hashpartitioner，可以通过重写hashpartitioner的getPartition方法来自定义分区规则。

之后会对key进行sort排序，grouping分组操作将相同key的value合并分组输出，在这里可以使用自定义的数据类型，重写WritableComparator的Comparator方法来自定义排序规则，重写RawComparator的compara方法来自定义分组规则。

之后进行一个combiner归约操作，就是一个本地的reduce预处理，以减小shuffle，reducer的工作量。

Reduce task会用过网络将各个数据收集进行reduce处理，最后将数据保存或者显示，结束整个job。


### 8、用mapreduce怎么处理数据倾斜问题

本质：让各分区的数据分布均匀

可以根据业务特点，设置合适的partition策略

如果事先根本不知道数据的分布规律，利用随机抽样器抽样后生成partition策略再处理


### 9、hive如何优化

排序优化：sort by 高于orderby

小文件合并大文件

打开map端的combine合并

使用静态分区，建立好分区一个分区对应hdfs上的一个目录，减少job和task数量：使用表连接操作

解决groupby 数据倾斜问题：设置hive.groupby.skewindata=true,那么hive会自动均衡负载，小文件合并为大文件：表连接操作，使用udf或udaf函数


### 10、Hadoop集群可以运行的3个模式？

单机（本地）模式

伪分布式模式

全分布式模式


### 11、Hbase宕机如何处理
### 12、在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。
### 13、Sqoop工作原理是什么？
### 14、sqoop在导入到MySQL中，如果不重复导入数据，如果数据存在问题，sqoop如何处理？
### 15、怎么样才能实现去掉reduce阶段
### 16、创建topic：
### 17、收集日志的模型
### 18、如何在浏览器中查找Namenode？
### 19、Hbase的rowKey怎么创建比较好？列簇怎么创建比较好？
### 20、hive底层与数据库交互原理
### 21、当前日志采样格式为
### 22、MapReduce运行原理
### 23、假设公司要建一个数据中心，你会如何处理？
### 24、hive能像关系型数据库那样建多个库吗？
### 25、启动和关闭命令会用到哪些文件？
### 26、hive为何分区
### 27、为什么SSH本地主机需要密码？
### 28、如何确定hadoop集群的健康状态
### 29、简单说一下hadoop和spark的shuffle过程
### 30、hive有哪些方式保存元数据，各有哪些优点
### 31、是客户端还是Namenode决定输入的分片？
### 32、RDD有哪些缺陷？




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)


## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
