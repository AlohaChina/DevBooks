# 大数据最新面试题及答案附答案汇总

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://github.com/souyunku/DevBooks/blob/master/docs/index.md)



### 1、hadoop数据倾斜及解决办法

**1、** 增加jvm内存,这适用于第一种情况(唯一值非常少，极少数值有非常多的记录值(唯一值少于几千)),这种情况下,往往只能通过硬件的手段来进行调优,增加jvm内存可以显著的提高运行效率。

**2、** 增加reduce的个数,这适用于第二种情况(唯一值比较多，这个字段的某些值有远远多于其他值的记录数，但是它的占比也小于百分之一或千分之一),我们知道,这种情况下,最容易造成的结果就是大量相同key被partition到一个分区,从而一个reduce执行了大量的工作,而如果我们增加了reduce的个数,这种情况相对来说会减轻很多,毕竟计算的节点多了,就算工作量还是不均匀的,那也要小很多。

**3、** 自定义分区,这需要用户自己继承partition类,指定分区策略,这种方式效果比较显著。

**4、** 重新设计key,有一种方案是在map阶段时给key加上一个随机数,有了随机数的key就不会被大量的分配到同一节点(小几率),待到reduce后再把随机数去掉即可。

**5、** 使用combinner合并,combinner是在map阶段,reduce之前的一个中间阶段,在这个阶段可以选择性的把大量的相同key数据先进行一个合并,可以看做是local reduce,然后再交给reduce来处理,这样做的好处很多,即减轻了map端向reduce端发送的数据量（减轻了网络带宽）,也减轻了map端和reduce端中间的shuffle阶段的数据拉取数量(本地化磁盘IO速率),推荐使用这种方法。


### 2、说一下RDD 的Lineage血统

RDD的lineage会记录RDD的元数据信息和转换行为，当该RDD 的部分分区数据丢失时，他可以根据这些信息来重新运算和恢复丢失数据


### 3、创建topic：

./Kafka-topic.sh --create --partition 3 --replication-factor 2 --topic test --zookeeper node01:2181,node2:2181,node3:2181


### 4、Kafka 各组件介绍

producer：生产者，push数据到Kafka集群

topic：一类消息的高级抽象，一类消息的集合，每个topic被分为多个partition

partition：分区的概念，存放在多个不同的服务器上，实现数据的横向扩展

broker：Kafka服务器，一个broker就代表一个服务器的节点

repliaction：副本，所有的分区可以指定存放几个副本，做到数据冗余，保证数据安全

segment：每个分区由多个segment组成，segment由 .log 文件，一个 .index文件。

**1、** s存储多条信息，消息id由其逻辑位置决定，即通过id可以直接查询到消息的存储位置，避免id的额外映射

**2、** 当segment消息条数到达配置值或消息发布时机超过阈值，segment会被flush到磁盘

**3、** 默认值1G，超过1G将节点将重新建立segment

.log:存放我们的日志文件，所有的数据，最后都以日志文件的形式存放到Kafka集群中

.index:索引文件，存放所有。log的索引，偏于我们查询


### 5、spark调优

**1、** 避免创建重复RDD

**2、** 尽可能复用同一个RDD

**3、** 对多次使用的RDD进行持久化

**4、** 避免使用shuffle算子

**5、** 使用map-side预聚合shuffle操作

**6、** 使用高性能的算子

**7、** 广播大变量

**8、** 使用Kryo序列化

**9、** 优化数据结构


### 6、请列出你所知道的hadoop调度器，并简要说明其工作方法

Fifo schedular :默认，先进先出的原则

Capacity schedular :计算能力调度器，选择占用最小、优先级高的先执行，依此类推。

Fair schedular:公平调度，所有的 job 具有相同的资源。


### 7、hadoop进程名

Datanode

负责存储文件

a.DataNode的需要完成的首要任务是K-V存储

b.完成和namenode 通信 ，这个通过IPC 心跳连接实现。

此外还有和客户端 其它datanode之前的信息交换

c.完成和客户端还有其它节点的大规模通信，这个需要直接

通过socket 协议实现。

SecondaryNamenode

合并快照

namenode

相当于一个领导者，负责调度

NodeManager

是YARN中每个节点上的代理，它管理Hadoop集群中单个计算节点

包括与ResourceManger保持通信，监督Container的生命周期管理，

监控每个Container的资源使用（内存、CPU等）情况，追踪节点健

康状况，管理日志和不同应用程序用到的附属服务（auxiliary service）

ResourceManager

在YARN中，ResourceManager负责集群中所有资源的统一管理和分配，它接收来自各个节点（NodeManager）的资源汇报信息，并把这些信息按照一定的策略分配给各个应用程序（实际上是ApplicationManager）

RM与每个节点的NodeManagers (NMs)和每个应用的ApplicationMasters (AMs)一起工作。

a.NodeManagers 遵循来自ResourceManager的指令来管理单一节点上的可用资源。

b.ApplicationMasters负责与ResourceManager协商资源与NodeManagers合作启动容器


### 8、过滤器有什么用途：

增强hbase查询数据的功能

减少服务端返回给客户端的数据量

reduce之后数据的输出量有多大（结合具体场景，比如pi）

Sca阶段的增强日志（1.5T—2T）

过滤性质的mr程序，输出比输入少

解析性质的mr程序，输出比输入多（找共同朋友）


### 9、hive内部表和外部表的区别

Hive 向内部表导入数据时，会将数据移动到数据仓库指向的路径；若是外部表，数据的具体存放目录由用户建表时指定

在删除表的时候，内部表的元数据和数据会被一起删除，

而外部表只删除元数据，不删除数据。

这样外部表相对来说更加安全些，数据组织也更加灵活，方便共享源数据。


### 10、hbase过滤器实现原则

可以说一下过滤器的父类（比较过滤器，专用过滤器）


### 11、RDD缓存
### 12、那当下又该如何配置？
### 13、请你用最熟悉的语言编写mapreduce，计算第四列每个元素出现的个数
### 14、“jps”命令的用处？
### 15、那些RDD 需要cache
### 16、如何确认hadoop集群的健康状况
### 17、请写出以下的shell命令
### 18、Hadoop集群可以运行的3个模式？
### 19、hadoop 的 namenode 宕机怎么解决
### 20、怎么保证Kafka集群的负载均衡？
### 21、KafkaUtils.createDstream 和 KafkaUtils.createDirectstream 区别
### 22、storm怎么保障消息不丢失
### 23、combine出现在哪个过程
### 24、请列出你所知道的hadoop调度器，并简要说明其工作方法？
### 25、怎么设置RDD cache
### 26、MapReduce的map数量和reduce数量怎么确定，怎么配置
### 27、请用java实现非递归二分查询
### 28、MR程序运行的时候会有什么比较常见的问题？
### 29、如果在SSH中添加key，是否还需要设置密码？
### 30、hive数仓开发的基本流程
### 31、shuffle阶段你怎么理解
### 32、hadoop中常用的数据压缩算法




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)




## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
