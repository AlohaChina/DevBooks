# 大数据最新面试题及答案附答案汇总

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://github.com/souyunku/DevBooks/blob/master/docs/index.md)



### 1、hive 跟hbase的区别

共同点都是用hadoop作为底层存储

区别：hive是为了减少mrjobs编写工作的批处理系统，处理速度慢。hive本身不存储数据和计算数据，依赖于hadoop，纯逻辑表

hbase是为了hadoop对实时操作的缺陷的项目，处理速度快，是物理表，提供一个超大的内存hash表，方便查询操作

如果全表扫描用 hive+hadoop

如果用索引查询与hbase+hadoop

是处理数据库文件还是读取文本文件

先读取文本文件进行清洗，然后放入hdfs，进行处理

或者直接读取MySQL中格式化数据


### 2、combine出现在哪个过程

shuffle过程中

具体来说，是在maptask输出的数据从内存溢出到磁盘，可能会调多次

Combiner使用时候要特别谨慎，不能影响最后的逻辑结果


### 3、请你用最熟悉的语言编写mapreduce，计算第四列每个元素出现的个数



```
public classWordCount1 {

public static final String INPUT_PATH ="hdfs://hadoop0:9000/in";

public static final String OUT_PATH ="hdfs://hadoop0:9000/out";

public static void main(String[] args)throws Exception {

      Configuration conf = newConfiguration();

      FileSystem fileSystem =FileSystem.get(conf);

      if(fileSystem.exists(newPath(OUT_PATH))){}

      fileSystem.delete(newPath(OUT_PATH),true);

      Job job = newJob(conf,WordCount1.class.getSimpleName());

      //1.0读取文件，解析成key,value对

      FileInputFormat.setInputPaths(job,newPath(INPUT_PATH));

      //2.0写上自己的逻辑，对输入的可以，value进行处理，转换成新的key,value对进行输出

      job.setMapperClass(MyMapper.class);

      job.setMapOutputKeyClass(Text.class);

      job.setMapOutputValueClass(LongWritable.class);

      //3.0对输出后的数据进行分区

      //4.0对分区后的数据进行排序，分组，相同key的value放到一个集合中

      //5.0对分组后的数据进行规约

      //6.0对通过网络将map输出的数据拷贝到reduce节点

      //7.0 写上自己的reduce函数逻辑，对map输出的数据进行处理

      job.setReducerClass(MyReducer.class);

      job.setOutputKeyClass(Text.class);

      job.setOutputValueClass(LongWritable.class);

      FileOutputFormat.setOutputPath(job,new Path(OUT_PATH));

      job.waitForCompletion(true);

}

static class MyMapper extendsMapper<LongWritable, Text, Text, LongWritable>{

      @Override

      protected void map(LongWritablek1, Text v1,

                    org.apache.hadoop.mapreduce.Mapper.Contextcontext)

                    throws IOException,InterruptedException {

             String[] split =v1.toString().split("\t");

             for(String words :split){

                    context.write(split[3],1);

             }

      }

}

static class MyReducer extends Reducer<Text,LongWritable, Text, LongWritable>{



      protected void reduce(Text k2,Iterable<LongWritable> v2,

                    org.apache.hadoop.mapreduce.Reducer.Contextcontext)

                    throws IOException,InterruptedException {

             Long count = 0L;

             for(LongWritable time :v2){

                    count += time.get();

             }

             context.write(v2, newLongWritable(count));

      }

}

}
```


### 4、mapreduce的原理

mapreduce的原理就是将一个MapReduce框架由一个单独的master JobTracker和每个集群节点一个slave TaskTracker共同组成。master负责调度构成一个作业的所有任务，这些的slave上，master监控它们的执行，重新执行已经失败的任务。而slave仅负责执行由maste指派的任务。


### 5、hadoop中常用的数据压缩算法

Lzo

Gzip

Default

Snapyy

如果要对数据进行压缩，最好是将原始数据转为SequenceFile 或者 Parquet File（spark）


### 6、spark的优化怎么做？

spark调优比较复杂，但是大体可以分为三个方面来进行

平台层面的调优：防止不必要的jar包分发，提高数据的本地性，选择高效的存储格式如parquet

应用程序层面的调优：过滤操作符的优化降低过多小任务，降低单条记录的资源开销，处理数据倾斜，复用RDD进行缓存，作业并行化执行等等

JVM层面的调优：设置合适的资源量，设置合理的JVM，启用高效的序列化方法如kyro，增大off head内存等等


### 7、Hive中存放是什么？

表。

存的是和hdfs的映射关系，hive是逻辑上的数据仓库，实际操作的都是hdfs上的文件，HQL就是用sql语法来写的mr程序。


### 8、hbase和hive的区别
### 9、SSH中的注意点还包括？
### 10、怎么在海量数据中找出重复次数最多的一个？
### 11、Hadoop的shuffle过程
### 12、简要描述如何安装配置apache的一个开源hadoop，只描述即可，无需列出具体步骤，列出具体步骤更好。
### 13、hadoop-env.sh是用于做什么的？
### 14、HDFS读取文件的步骤
### 15、请简述hadoop怎样实现二级排序（就是对key和value双排序）
### 16、Namenode、Job tracker和task tracker的端口号是？
### 17、hive的内表和外表
### 18、怎么设置RDD cache
### 19、为什么会产生RDD
### 20、hdfs运行原理
### 21、如何在浏览器中查找Namenode？
### 22、简述hive中的虚拟列的作用？使用它注意事项
### 23、数据库 OLAP OLTP的介绍和比较
### 24、使用zk来连接集群
### 25、HBase简单读写流程？
### 26、简单说一下hadoop和spark的shuffle过程
### 27、combiner出现在哪个过程
### 28、Hadoop安装在什么目录下？
### 29、如何知道消费者消费到哪一条消息了？
### 30、sqoop在导入到MySQL中，如果不重复导入数据，如果数据存在问题，sqoop如何处理？
### 31、你认为用java ， streaming ， pipe方式开发map/reduce ， 各有哪些优点
### 32、RDD 是什么




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)




## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
