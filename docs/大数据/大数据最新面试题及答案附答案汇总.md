# 大数据最新面试题及答案附答案汇总

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)



### 1、hdfs的体系结构

集群架构：

namenode datanode secondarynamenode

(active namenode ,standby namenode)journalnode zkfc

内部工作机制：

数据是分布式存储的

对外提供一个统一的目录结构

对外提供一个具体的响应者（namenode）

数据的block机制，副本机制

Namenode和datanode的工作职责和机制

读写数据流程


### 2、Hadoop是否遵循UNIX模式？

是的，在UNIX用例下，Hadoop还拥有“conf”目录。


### 3、MR程序运行的时候会有什么比较常见的问题？

比如说作业中大部分都完成了，但是总有几个reduce一直在运行。

这是因为这几个reduce中的处理的数据要远远大于其他的reduce，可能是对键值对任务划分的不均匀造成的数据倾斜。

解决的方法可以在分区的时候重新定义分区规则对于value数据很多的key可以进行拆分、均匀打散等处理，或者是在map端的combiner中进行数据预处理的操作。


### 4、mapreduce作业，不让reduce输出，用什么代替reduce的功能。

hive如何调优

hive最终都会转化为mapreduce的job来运行，要想hive调优，实际上就是mapreduce调优，可以有下面几个方面的调优。解决收据倾斜问题，减少job数量，设置合理的map和reduce个数，对小文件进行合并，优化时把握整体，单个task最优不如整体最优。按照一定规则分区。


### 5、生产环境为什么建议使用外部表

**1、** 因为表数据不会加载到hive，减少数据传输，数据能共享

**2、** hive不会修改数据，所以无需担心数据损坏

**3、** 删除表示，只删除表结构，不删除数据


### 6、当你输入hadoopfsck 造成“connection refused java exception’”时，系统究竟发生了什么？

这意味着Namenode没有运行在你的VM之上。


### 7、在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。

方案1：采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）进行，共需内存2^32 * 2 bit=1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。

方案2：也可采用与第1题类似的方法，进行划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。


### 8、请描述一下开发过程中如何对上面的程序进行性能分析，对性能分析进行优化的过程。

现有 1 亿个整数均匀分布，如果要得到前 1K 个最大的数，求最优的算法。

参见《海量数据算法面试大全》

95.mapreduce的大致流程

主要分为八个步骤

1/对文件进行切片规划

2/启动相应数量的maptask进程

3/调用FileInputFormat中的RecordReader，读一行数据并封装为k1v1

4/调用自定义的map函数，并将k1v1传给map

5/收集map的输出，进行分区和排序

6/reduce task任务启动，并从map端拉取数据

7/reduce task调用自定义的reduce函数进行处理

8/调用outputformat的recordwriter将结果数据输出


### 9、那当下又该如何配置？

Hadoop现在拥有3个配置文件：1，core-site.xml；2，hdfs-site.xml；3，mapred-site.xml。这些文件都保存在conf子目录下。


### 10、请用java实现非递归二分查询

```
public class BinarySearchClass

{

public static int binary_search(int[] array, int value)

{

 int beginIndex = 0;// 低位下标

 int endIndex = array.length - 1;// 高位下标

 int midIndex = -1;

 while (beginIndex <= endIndex) {

     midIndex = beginIndex + (endIndex - beginIndex) / 2;//防止溢出

     if (value == array[midIndex]) {

         return midIndex;

     } else if (value < array[midIndex]) {

         endIndex = midIndex - 1;

     } else {

         beginIndex = midIndex + 1;

     }

 }

 return -1;

 //找到了，返回找到的数值的下标，没找到，返回-1

}

//start 提示：自动阅卷起始唯一标识，请勿删除或增加。

public static void main(String[] args)

{

 System.out.println("Start...");

 int[] myArray = new int[] { 1, 2, 3, 5, 6, 7, 8, 9 };

 System.out.println("查找数字8的下标：");

 System.out.println(binary_search(myArray, 8));

}

//end //提示：自动阅卷结束唯一标识，请勿删除或增加。

}
```


### 11、假如一个分区的数据逐步错误怎么通过hivesql删除
### 12、hadoop 的 namenode 宕机怎么解决
### 13、什么是队列
### 14、pig , latin , hive语法有什么不同
### 15、为什么要用flume导入hdfs，hdfs的构架是怎样的
### 16、Kafka与传统消息队列的区别
### 17、hive 跟hbase的区别
### 18、运行hadoop集群需要哪些守护进程？
### 19、hadoop中常用的数据压缩算法
### 20、怎么保证Kafka集群的负载均衡？
### 21、一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。
### 22、“jps”命令的用处？
### 23、Fsck的全名？
### 24、Masters由什么组成？
### 25、简答说一下hadoop的map-reduce编程模型
### 26、我们开发Job是否能去掉reduce阶段
### 27、请写出以下的shell命令
### 28、Hive中存放是什么？
### 29、我们使用Ubuntu及Cloudera，那么我们该去哪里下载Hadoop，或者是默认就与Ubuntu一起安装？
### 30、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
### 31、为什么要用flume导入hdfs，hdfs的架构是怎样的？
### 32、SSH中的注意点还包括？




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)


## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "大厂面试题")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png"大厂面试题")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
