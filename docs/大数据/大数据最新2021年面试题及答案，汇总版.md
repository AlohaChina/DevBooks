# 大数据最新2021年面试题及答案，汇总版

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://github.com/souyunku/DevBooks/blob/master/docs/index.md)



### 1、请简述hadoop怎样实现二级排序（就是对key和value双排序）

第一种方法是，Reducer将给定key的所有值都缓存起来，然后对它们再做一个Reducer内排序。但是，由于Reducer需要保存给定key的所有值，可能会导致出现内存耗尽的错误。

第二种方法是，将值的一部分或整个值加入原始key，生成一个组合key。这两种方法各有优势，第一种方法编写简单，但并发度小，数据量大的情况下速度慢(有内存耗尽的危险)，

第二种方法则是将排序的任务交给MapReduce框架shuffle，更符合Hadoop/Reduce的设计思想。这篇文章里选择的是第二种。我们将编写一个Partitioner，确保拥有相同key(原始key，不包括添加的部分)的所有数据被发往同一个Reducer，还将编写一个Comparator，以便数据到达Reducer后即按原始key分组。

68.简述hadoop实现jion的几种方法

Map side join----大小表join的场景，可以借助distributed cache

Reduce side join


### 2、请列出正常的hadoop集群中hadoop都分别需要启动 哪些进程，他们的作用分别都是什么，请尽量列的详细一些。

namenode：负责管理hdfs中文件块的元数据，响应客户端请求，管理datanode上文件block的均衡，维持副本数量

Secondname:主要负责做checkpoint操作；也可以做冷备，对一定范围内数据做快照性备份。

Datanode:存储数据块，负责客户端对数据块的io请求

Jobtracker :管理任务，并将任务分配给 tasktracker。

Tasktracker: 执行JobTracker分配的任务。

Resourcemanager

Nodemanager

Journalnode

Zookeeper

Zkfc


### 3、offset是每天消息的偏移量

每个日志文件都有一个offset来唯一标记一条信息，由8个自己数字表示，表示此消息在分区中所处的起始位置

每个分区再物理存储层面，由多个logfile组成（segment）

最小的offset表示segment中起始消息的offset


### 4、mapred.job.tracker命令的作用？

可以让你知道哪个节点是Job Tracker。


### 5、为什么hive的分区

为了避免select扫描全表，hive提出了分区表partitionedby的概念，给文件归类打上表示

**静态分区：**

单分区建表

create table par_tab(name string,nation string) partitioned by (sex string) row format delimited fields terminated by ‘,’;

加载：load data local inpath ‘/hdfs/…’ into table par_tab partition(sex=‘man’)

在创建分区表的时候，系统会在hive数据仓库默认路径/user/hive/warehouse/创建目录，在创建sex=man的目录，最后在分区名下存放实际的数据文件

**多分区建表**

create table par_tab(name string,nation string) partitioned by (sex string,dt string) row format delimited fields terminated by ',';

load data local inpath '/hdfs/...' into table par_tab partition(sex='man',dt="2019-08-08")

当我们查询所有的man时候，man一下的所有日期下的数据都会被查出来；如果只查询日期分区，那么hive会对路径进行修剪，从而只扫描日期分区，性别分区不做过滤

动态分区

动态分区与静态分区区别就是不指定分区目录，有系统自己选择

开启动态分区 set hive.exec.dynamic.partition=true


### 6、为什么要用flume导入hdfs，hdfs的架构是怎样的？

Flume可以实时的导入数据到hdfs中，当hdfs上的文件达到一个指定大小的时候会形成一个文件，或者超时所指定时间的话也形成一个文件。

文件都是存储在datanode上的，namenode存储着datanode的元数据信息，而namenode的元数据信息是存在内存中的，所以当文件切片很小或者很多的时候会卡死。


### 7、当前日志采样格式为

a , b , c , d

b , b , f , e

a , a , c , f


### 8、pig , latin , hive语法有什么不同


### 9、SSH中的注意点还包括？

SSH只是个安全的shell通信，可以把它当做NO.22上的一种协议，只需要配置一个密码就可以安全的访问。


### 10、如何解决spark数据倾斜

**1、** 使用ETL预处理

**2、** 过滤少数导致倾斜的key

**3、** 提高shuffle操作并行度

**4、** 两阶段聚合 阶段聚合 和 全局聚合


### 11、什么是DAG
### 12、Hadoop是否遵循UNIX模式？
### 13、我们开发Job是否能去掉reduce阶段
### 14、Hbase行键列族的概念，物理模型，表的设计原则？
### 15、Flume的工作及时是什么？
### 16、什么是spark
### 17、数据本地性是在哪个环节确定的？
### 18、什么是队列
### 19、介绍一下hbase
### 20、如何检查Namenode是否正常运行？
### 21、什么是Kafka？
### 22、上千万或上亿数据（有重复），统计其中出现次数最多的前N个数据。
### 23、查看所有的topic
### 24、你们数据库如何导入hive的出现什么错误
### 25、hive为何分区
### 26、如何退出输入模式？
### 27、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？
### 28、为什么会产生RDD
### 29、Fsck的全名？
### 30、有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。
### 31、HDFS写文件的步骤：
### 32、宕机分为HMaster宕机和HRegisoner宕机，如果是HRegisoner宕机，HMaster会将其所管理的region重新分布到其他活动的RegionServer上，由于数据和日志都持久在HDFS中，该操作不会导致数据丢失。所以数据的一致性和安全性是有保障的。




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin-2.png)




## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
