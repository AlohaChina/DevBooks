# 大数据最新2021年面试题及答案，汇总版

### 其实，博主还整理了，更多大厂面试题，直接下载吧

### 下载链接：[高清172份，累计 7701 页大厂面试题  PDF](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)



### 1、是否可以自行搭建Hadoop集群？

是的，只要对Hadoop环境足够熟悉，你完全可以这么做。


### 2、描述Hbase的rowkey的设计原则

**1、** rowkey长度原则：设计为定长，如果rowkey过长，内存使用率降低，会降低检索效率

**2、** rowkey散列原则：将rowkey的高位作为散列字段，有程序随机生成，这样将提高数据均衡分布在每个RegionServer上，以实现负载均衡。

如果没有散列字段，所有数据就会集中在一个RegionServer上，数据检索时负载会集中在个别RegionServer上，造成热点问题，降低效率

**3、** rowkey唯一原则：必须在设计上保证唯一性，rowkey是按照字段顺序排序存储的，设计rowkey时，充分利用排序这个特点，将经常读取的数据存在一块，可能被访问的数据放在一起


### 3、RDD有哪些缺陷？

不支持细粒度的写和更新操作（如网络爬虫），spark写数据是粗粒度的。所谓粗粒度，就是批量写入数据，为了提高效率。但是读数据是细粒度的也就是说可以一条条的读。

不支持增量迭代计算，Flink支持


### 4、过滤器有什么用途：

增强hbase查询数据的功能

减少服务端返回给客户端的数据量

reduce之后数据的输出量有多大（结合具体场景，比如pi）

Sca阶段的增强日志（1.5T—2T）

过滤性质的mr程序，输出比输入少

解析性质的mr程序，输出比输入多（找共同朋友）


### 5、假如一个分区的数据逐步错误怎么通过hivesql删除

alter table ptable drop partition(daytime=‘20140921’,city=‘bj’);全部删除，文件夹还在


### 6、请列举出曾经修改过的/etc/下面的文件，并说明修改要解决什么问题？

/etc/profile这个文件，主要是用来配置环境变量。让hadoop命令可以在任意目录下面执行。

/ect/sudoers

/etc/hosts

/etc/sysconfig/network

/etc/inittab


### 7、有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。

还是典型的TOP K算法，解决方案如下：

方案1：

顺序读取10个文件，按照hash(query)的结果将query写入到另外10个文件（记为）中。这样新生成的文件每个的大小大约也1G（假设hash函数是随机的）。

找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。利用快速/堆/归并排序按照出现次数进行排序。将排序好的query和对应的query_cout输出到文件中。这样得到了10个排好序的文件（记为）。

对这10个文件进行归并排序（内排序与外排序相结合）。

方案2：

一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树/hash_map等直接来统计每个query出现的次数，然后按出现次数做快速/堆/归并排序就可以了。

方案3：

与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理（比如MapReduce），最后再进行合并。


### 8、我们开发Job是否能去掉reduce阶段

可以去掉。设置reduce数为0即可


### 9、简述hive中的虚拟列的作用？使用它注意事项

三个虚拟列

INPUT_FILE_NAME：mapper任务的输出文件名

BLOCK_OFFSET_INSIDE_FILE：当前全局文件偏移量，对于快压缩文件，就是当前快的文件偏移量，及当前块的第一个字节在文件中的偏移量

ROW_OFFSET_INSIDE_BLOCK，默认不开启，设置hive.exec.rowoffset为true可用，可以用来排查有问题的输入数据


### 10、数据的三范式

第一范式（）无重复的列

第二范式（2NF）属性完全依赖于主键 [消除部分子函数依赖]

第三范式（3NF）属性不依赖于其它非主属性 [消除传递依赖]


### 11、hbase过滤器实现原则
### 12、spark的优化怎么做？
### 13、Hive与关系型数据库的关系？
### 14、数据本地性是在哪个环节确定的？
### 15、Hive与关系型数据库的关系？
### 16、Kafka 各组件介绍
### 17、如何检查Namenode是否正常运行？
### 18、谈谈Zookeeper理解
### 19、请写出以下的shell命令
### 20、为什么hive的分区
### 21、如果在SSH中添加key，是否还需要设置密码？
### 22、HBase的特点是什么？
### 23、Spark的数据本地性有哪几种？
### 24、hive的内表和外表
### 25、解释下hbase实时查询原理
### 26、Kafka的消费
### 27、用mapreduce实现sql语 select count (x) from a group by b;
### 28、Flume的工作及时是什么？
### 29、pig , latin , hive语法有什么不同
### 30、Hadoop安装在什么目录下？
### 31、sqoop在导入到MySQL中，如果不重复导入数据，如果数据存在问题，sqoop如何处理？
### 32、是客户端还是Namenode决定输入的分片？




## 全部答案，整理好了，直接下载吧

### 下载链接：[全部答案，整理好了](https://www.souyunku.com/?p=67)

### 一键直达：[https://www.souyunku.com/?p=67](https://www.souyunku.com/?p=67)


## 最新，高清PDF：172份，7701页，最新整理

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/mst.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")

[![大厂面试题](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")](https://www.souyunku.com/wp-content/uploads/weixin/githup-weixin.png "架构师专栏")
